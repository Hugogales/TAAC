# Model loading (optional)
# Set this to continue training from an existing model or for view.py
load_model: null  # Example: "files/Models/cooking_zoo/best_model.pth"

environment:
  name: cooking_zoo
  env_kwargs:
    num_agents: 2
    recipe_id: "TomatoSalad"  # Start with simple recipe
    max_steps: 200
    obs_spaces: null  # Use default observation spaces
    action_scheme: "scheme1"  # Default action scheme
  apply_wrappers: true

training:
  episodes: 2000
  max_steps_per_episode: 200
  gamma: 0.99
  learning_rate: 3e-4
  epsilon_clip: 0.2
  K_epochs: 8
  c_entropy: 0.02  # Higher entropy for exploration in cooperative tasks
  max_grad_norm: 0.5
  c_value: 0.5
  lam: 0.95
  batch_size: 64
  min_learning_rate: 1e-6
  similarity_loss_coef: 0.2  # Higher for encouraging cooperation
  num_parallel: 4  # Number of parallel environments (4 good for cooperative tasks)

# Model Architecture
model:
  num_heads: 4
  embedding_dim: 256
  hidden_size: 526

# Logging & Evaluation
logging:
  log_interval: 10      # Print stats every N episodes
  save_interval: 100    # Save model every N episodes  
  eval_interval: 50     # Evaluate model every N episodes
  eval_episodes: 5      # Number of episodes for evaluation

# Output Configuration
output:
  experiment_name: "cooking_zoo_experiment"
  model_save_path: "files/Models/cooking_zoo/"
  log_save_path: "experiments/cooking_zoo/"

# Environment-specific notes:
# - CookingZoo requires coordination between agents
# - Higher similarity_loss_coef encourages cooperation
# - Higher entropy promotes exploration of coordination strategies
# - Recipe_id can be changed: "TomatoSalad", "LettuceWrap", "LobsterPlate", etc. 